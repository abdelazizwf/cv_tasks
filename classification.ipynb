{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mlflow\n",
    "import lightning as L\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"./datasets/classification/\"\n",
    "TRAIN_PATH = ROOT_PATH + \"train/\"\n",
    "VAL_PATH = ROOT_PATH + \"val/\"\n",
    "IMAGE_SIZE = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    to_tensor,\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    to_tensor,\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(TRAIN_PATH, transform=train_transforms)\n",
    "val_dataset = ImageFolder(VAL_PATH, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=11)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = partial(nn.Conv2d, kernel_size=3, stride=1, padding=\"same\")\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, inp, l1, l2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            conv2d(inp, l1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(l1),\n",
    "            conv2d(l1, l2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(l2),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class CNN(L.LightningModule):\n",
    "    def __init__(self, lr, momentum, criterion=F.cross_entropy):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            ConvBlock(3, 8, 16),\n",
    "            ConvBlock(16, 32, 64),\n",
    "            ConvBlock(64, 128, 256),\n",
    "            nn.AvgPool2d(16),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 5)\n",
    "        )\n",
    "        \n",
    "        self.step_losses = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_hat = self(X)\n",
    "        loss = self.hparams.criterion(y_hat, y)\n",
    "        self.step_losses.append(loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.parameters(), lr=self.hparams.lr, momentum=self.hparams.momentum)\n",
    "        return optimizer\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        mean_loss = torch.stack(self.step_losses).mean()\n",
    "        mlflow.log_metric(\"train_loss\", mean_loss.item(), step=self.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/01 04:41:26 INFO mlflow.tracking.fluent: Experiment with name '/cv-project-1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/235196971337957232', creation_time=1738377686377, experiment_id='235196971337957232', last_update_time=1738377686377, lifecycle_stage='active', name='/cv-project-1', tags={}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"/cv-project-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = CNN(0.01, 0.9)\n",
    "trainer = L.Trainer(max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | layers | Sequential | 395 K  | train\n",
      "----------------------------------------------\n",
      "395 K     Trainable params\n",
      "0         Non-trainable params\n",
      "395 K     Total params\n",
      "1.583     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/abdelazizwf/.pyenv/versions/3.11.4/envs/cv_project/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (37) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 37/37 [00:04<00:00,  8.95it/s, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 37/37 [00:04<00:00,  8.77it/s, v_num=3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/01 05:02:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gentle-shark-403 at: http://localhost:5000/#/experiments/235196971337957232/runs/bbf7f02d220248da9b422c5a20498525\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/235196971337957232\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    params = {\n",
    "        \"epochs\": trainer.max_epochs,\n",
    "        \"lr\": model.hparams.lr,\n",
    "        \"momentum\": model.hparams.momentum,\n",
    "        \"criterion\": model.hparams.criterion.__name__,\n",
    "        \"optimizer\": \"SGD\",\n",
    "    }\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    from torchinfo import summary\n",
    "    \n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    \n",
    "    trainer.fit(model=model, train_dataloaders=train_dataloader)\n",
    "    \n",
    "    mlflow.pytorch.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
